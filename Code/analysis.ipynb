{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "DataSourceError",
     "evalue": "/Users/claireconzelmann/Documents/GitHub/KIHC-affordable-housing-analysis/Code/Data/Processed/tif_districts.shp: No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mDataSourceError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[43], line 8\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      6\u001b[0m path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mgetcwd()\n\u001b[0;32m----> 8\u001b[0m tif_districts_gdf \u001b[38;5;241m=\u001b[39m \u001b[43mgpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mData/Processed/tif_districts.shp\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m metra_lines_gdf \u001b[38;5;241m=\u001b[39m gpd\u001b[38;5;241m.\u001b[39mread_file(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData/Raw/MetraLinesshp.shp\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m     10\u001b[0m l_lines \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData/Raw/CTA_l_lines.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "File \u001b[0;32m~/Documents/GitHub/KIHC-affordable-housing-analysis/.venv/lib/python3.9/site-packages/geopandas/io/file.py:294\u001b[0m, in \u001b[0;36m_read_file\u001b[0;34m(filename, bbox, mask, columns, rows, engine, **kwargs)\u001b[0m\n\u001b[1;32m    291\u001b[0m             from_bytes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    293\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m engine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpyogrio\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 294\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read_file_pyogrio\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbbox\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbbox\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrows\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    298\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m engine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfiona\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    299\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mapi\u001b[38;5;241m.\u001b[39mtypes\u001b[38;5;241m.\u001b[39mis_file_like(filename):\n",
      "File \u001b[0;32m~/Documents/GitHub/KIHC-affordable-housing-analysis/.venv/lib/python3.9/site-packages/geopandas/io/file.py:547\u001b[0m, in \u001b[0;36m_read_file_pyogrio\u001b[0;34m(path_or_bytes, bbox, mask, rows, **kwargs)\u001b[0m\n\u001b[1;32m    538\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    539\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minclude_fields\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mignore_fields\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m keywords are deprecated, and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    540\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwill be removed in a future release. You can use the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m keyword \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    543\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,\n\u001b[1;32m    544\u001b[0m     )\n\u001b[1;32m    545\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minclude_fields\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 547\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpyogrio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_dataframe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_or_bytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbbox\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbbox\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/GitHub/KIHC-affordable-housing-analysis/.venv/lib/python3.9/site-packages/pyogrio/geopandas.py:265\u001b[0m, in \u001b[0;36mread_dataframe\u001b[0;34m(path_or_buffer, layer, encoding, columns, read_geometry, force_2d, skip_features, max_features, where, bbox, mask, fids, sql, sql_dialect, fid_as_index, use_arrow, on_invalid, arrow_to_pandas_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m use_arrow:\n\u001b[1;32m    261\u001b[0m     \u001b[38;5;66;03m# For arrow, datetimes are read as is.\u001b[39;00m\n\u001b[1;32m    262\u001b[0m     \u001b[38;5;66;03m# For numpy IO, datetimes are read as string values to preserve timezone info\u001b[39;00m\n\u001b[1;32m    263\u001b[0m     \u001b[38;5;66;03m# as numpy does not directly support timezones.\u001b[39;00m\n\u001b[1;32m    264\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdatetime_as_string\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 265\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mread_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    266\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlayer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mread_geometry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mread_geometry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgdal_force_2d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mskip_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskip_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwhere\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbbox\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbbox\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    276\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    277\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    278\u001b[0m \u001b[43m    \u001b[49m\u001b[43msql\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msql\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    279\u001b[0m \u001b[43m    \u001b[49m\u001b[43msql_dialect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msql_dialect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    280\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_fids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfid_as_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    281\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    282\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_arrow:\n\u001b[1;32m    285\u001b[0m     meta, table \u001b[38;5;241m=\u001b[39m result\n",
      "File \u001b[0;32m~/Documents/GitHub/KIHC-affordable-housing-analysis/.venv/lib/python3.9/site-packages/pyogrio/raw.py:198\u001b[0m, in \u001b[0;36mread\u001b[0;34m(path_or_buffer, layer, encoding, columns, read_geometry, force_2d, skip_features, max_features, where, bbox, mask, fids, sql, sql_dialect, return_fids, datetime_as_string, **kwargs)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Read OGR data source into numpy arrays.\u001b[39;00m\n\u001b[1;32m     60\u001b[0m \n\u001b[1;32m     61\u001b[0m \u001b[38;5;124;03mIMPORTANT: non-linear geometry types (e.g., MultiSurface) are converted\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    194\u001b[0m \n\u001b[1;32m    195\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    196\u001b[0m dataset_kwargs \u001b[38;5;241m=\u001b[39m _preprocess_options_key_value(kwargs) \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[0;32m--> 198\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mogr_read\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m    \u001b[49m\u001b[43mget_vsi_path_or_buffer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_or_buffer\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlayer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    203\u001b[0m \u001b[43m    \u001b[49m\u001b[43mread_geometry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mread_geometry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    204\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_2d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    205\u001b[0m \u001b[43m    \u001b[49m\u001b[43mskip_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskip_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    206\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_features\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    207\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwhere\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    208\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbbox\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbbox\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    209\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_mask_to_wkb\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    210\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    211\u001b[0m \u001b[43m    \u001b[49m\u001b[43msql\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msql\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    212\u001b[0m \u001b[43m    \u001b[49m\u001b[43msql_dialect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msql_dialect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    213\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_fids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_fids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    215\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdatetime_as_string\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdatetime_as_string\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    216\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32mpyogrio/_io.pyx:1240\u001b[0m, in \u001b[0;36mpyogrio._io.ogr_read\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpyogrio/_io.pyx:220\u001b[0m, in \u001b[0;36mpyogrio._io.ogr_open\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mDataSourceError\u001b[0m: /Users/claireconzelmann/Documents/GitHub/KIHC-affordable-housing-analysis/Code/Data/Processed/tif_districts.shp: No such file or directory"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "path = os.getcwd()\n",
    "\n",
    "tif_districts_gdf = gpd.read_file(os.path.join(path, \"Data/Processed/tif_districts.shp\"))\n",
    "metra_lines_gdf = gpd.read_file(os.path.join(path, \"Data/Raw/MetraLinesshp.shp\"))\n",
    "l_lines = pd.read_csv(os.path.join(path, \"Data/Raw/CTA_l_lines.csv\"))\n",
    "bus_routes_gdf = gpd.read_file(os.path.join(path, \"Data/Processed/bus_routes.shp\"))\n",
    "etod_lots_tifs = gpd.read_file(os.path.join(path, \"Data/Processed/etod_lots_tifs.shp\"))\n",
    "neighborhoods = pd.read_csv(os.path.join(path, \"Data/Raw/Neighborhoods.csv\"))\n",
    "unit_area = pd.read_csv(os.path.join(path, \"Data/Raw/zone min unit area.csv\"))\n",
    "\n",
    "sale_buildings_gdf = gpd.read_file(os.path.join(path, \"Data/Processed/sale_buildings.shp\"))\n",
    "vacant_buildings_gdf = gpd.read_file(os.path.join(path, \"Data/Processed/vacant_buildings.shp\"))\n",
    "merged_neighborhoods_gdf = gpd.read_file(os.path.join(path, \"Data/Processed/neighborhood_level.shp\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/claireconzelmann/Documents/GitHub/KIHC-affordable-housing-analysis/Code/..'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = os.path.join(os.getcwd(), \"..\")\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge FAR and min unit area info\n",
    "etod_lots_tifs.replace({\"sq_ft\": 0.0}, np.nan, inplace=True)\n",
    "etod_lots_tifs = pd.merge(etod_lots_tifs, unit_area, on=\"zoning\", how=\"outer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#assume 20% of all lot square footage cannot be used for unit calculation\n",
    "etod_lots_tifs[\"sq_ft_rentable\"] = etod_lots_tifs[\"sq_ft\"]*0.8\n",
    "\n",
    "#update sqft based on far\n",
    "etod_lots_tifs[\"sq_ft_far\"] = etod_lots_tifs[\"sq_ft_rentable\"]*etod_lots_tifs[\"FAR\"]\n",
    "\n",
    "#for non residential zoned lots, calculate sq footage above ground floor\n",
    "etod_lots_tifs[\"sq_ft_residential\"] = np.where((etod_lots_tifs[\"zone_cat\"]==\"B-Business\") |\n",
    "                                               (etod_lots_tifs[\"zone_cat\"]==\"C-Commercial\"), \n",
    "                                               etod_lots_tifs[\"sq_ft_far\"] - etod_lots_tifs[\"sq_ft_rentable\"], \n",
    "                                               etod_lots_tifs[\"sq_ft_far\"])\n",
    "\n",
    "#assume 720 sq. ft. average unit size unless min unit size is larger\n",
    "etod_lots_tifs[\"avg_unit_size\"] = np.where(etod_lots_tifs[\"lot_area_per_unit\"] > 720, \n",
    "                                           etod_lots_tifs[\"lot_area_per_unit\"], 720)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate estimate of number of units per lot\n",
    "# 0 units if residential eligible sq ft is smaller than minimum unit size\n",
    "etod_lots_tifs[\"n_units\"] = np.where(etod_lots_tifs[\"avg_unit_size\"] > etod_lots_tifs[\"sq_ft_residential\"], 0, np.nan)\n",
    "\n",
    "# divide residential eligible sq ft by average unit size for all others and round down\n",
    "etod_lots_tifs[\"n_units\"] = np.where(etod_lots_tifs[\"n_units\"].isna(), \n",
    "                                     np.floor(etod_lots_tifs[\"sq_ft_residential\"]/etod_lots_tifs[\"avg_unit_size\"]), \n",
    "                                     etod_lots_tifs[\"n_units\"])\n",
    "\n",
    "# 1 unit for single family\n",
    "etod_lots_tifs[\"n_units\"] = np.where(etod_lots_tifs[\"zoning\"].isin([\"RS-1\", \"RS-2\", \"RS-3\"]), 1, etod_lots_tifs[\"n_units\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate average number of units by zone to impute for lots missing sqft info\n",
    "avg_units_zone = etod_lots_tifs.groupby(\"zoning\")[\"n_units\"].mean().reset_index(name=\"imputed_n_units\")\n",
    "etod_lots_tifs = pd.merge(etod_lots_tifs, avg_units_zone, on=\"zoning\", how=\"outer\")\n",
    "\n",
    "# impute\n",
    "etod_lots_tifs[\"n_units\"] = np.where(etod_lots_tifs[\"n_units\"].isna(), \n",
    "                                     np.floor(etod_lots_tifs[\"imputed_n_units\"]),\n",
    "                                     etod_lots_tifs[\"n_units\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(35287.0)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "etod_lots_tifs[\"n_units\"].sum(skipna=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate number of lots by zone and by neighborhood\n",
    "lots_by_zone_neigh = etod_lots_tifs.groupby([\"Community\", \"zoning\"]).size().reset_index(name=\"n_lots\")\n",
    "\n",
    "#calculate number of lots by neighborhood\n",
    "lots_by_neigh = etod_lots_tifs.groupby([\"Community\"]).size().reset_index(name=\"n_lots_neigh\")\n",
    "\n",
    "#calculate number of lots by zone category and neighborhood\n",
    "lots_by_zone_cat = etod_lots_tifs.groupby([\"Community\", \"zone_cat\"]).size().reset_index(name=\"n_lots_cat\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create broader category for zones\n",
    "zone_cats = {\"B-Business\":\"B\", \n",
    "             \"C-Commercial\":\"C\",\n",
    "             \"D-Downtown\": \"D\",\n",
    "             \"PD-Planned Development\":\"PD\",\n",
    "             \"R-Residential\":\"R\"}\n",
    "\n",
    "def map_category(item):\n",
    "    for key, value in zone_cats.items():\n",
    "        if item.startswith(value):  # Check if item starts with dictionary value\n",
    "            return key\n",
    "    return \"Unknown\"  # Default value if no match is found\n",
    "\n",
    "lots_by_zone_neigh[\"zone_cat\"] = lots_by_zone_neigh[\"zoning\"].apply(map_category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge all counts together\n",
    "n_lots_neigh_zone = pd.merge(lots_by_zone_neigh, lots_by_neigh, on=\"Community\", how=\"outer\")\n",
    "n_lots_neigh_zone = pd.merge(n_lots_neigh_zone, lots_by_zone_cat, on=[\"Community\", \"zone_cat\"], how=\"outer\")\n",
    "n_lots_neigh_zone = n_lots_neigh_zone.sort_values(by=[\"Community\", \"zoning\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_lots_neigh_zone.to_csv(os.path.join(path, \"Data/Processed/vacant_lots_zone_counts.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Analysis for buildings for sale and vacant buildings\n",
    "#Data Cleaning\n",
    "#renaming zones\n",
    "sale_buildings_gdf = sale_buildings_gdf.rename(columns={\"ZONE_CLASS\": \"zoning\"})\n",
    "vacant_buildings_gdf = vacant_buildings_gdf.rename(columns={\"ZONE_CLASS\": \"zoning\"})\n",
    "\n",
    "#data cleaning for square foot info \n",
    "sale_buildings_gdf['SqFt'] = sale_buildings_gdf['SqFt'].astype(str)\n",
    "vacant_buildings_gdf['SqFt'] = vacant_buildings_gdf['SqFt'].astype(str)\n",
    "\n",
    "sale_buildings_gdf['SqFt'] = pd.to_numeric(sale_buildings_gdf['SqFt'].str.replace(',', ''), errors='coerce')\n",
    "sale_buildings_gdf['SqFt'] = sale_buildings_gdf['SqFt'].fillna(0.0).astype(int)\n",
    "sale_buildings_gdf.replace({\"SqFt\": 0.0}, np.nan, inplace=True)\n",
    "\n",
    "sale_buildings_gdf[\"SqFt\"] = np.where(\n",
    "    sale_buildings_gdf[\"zoning\"].isin([\"RT-4\", \"RT-3.5\", \"RT-4A\"]) &\n",
    "    sale_buildings_gdf[\"SqFt\"].isna(),\n",
    "    1320, \n",
    "    sale_buildings_gdf[\"SqFt\"]  \n",
    ")\n",
    "\n",
    "vacant_buildings_gdf['SqFt'] = pd.to_numeric(vacant_buildings_gdf['SqFt'].str.replace(',', ''), errors='coerce')\n",
    "vacant_buildings_gdf['SqFt'] = vacant_buildings_gdf['SqFt'].fillna(0.0).astype(int)\n",
    "vacant_buildings_gdf.replace({\"SqFt\": 0.0}, np.nan, inplace=True)\n",
    "\n",
    "vacant_buildings_gdf[\"SqFt\"] = np.where(\n",
    "    vacant_buildings_gdf[\"zoning\"].isin([\"RT-4\", \"RT-3.5\", \"RT-4A\", \"RM-4.5\", \"RM-5\", \"RM-5.5\", \"RM-6.5\"]) &\n",
    "    vacant_buildings_gdf[\"SqFt\"].isna(),\n",
    "    1320,\n",
    "    vacant_buildings_gdf[\"SqFt\"]  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#merging with unit area data\n",
    "sale_buildings_gdf = pd.merge(sale_buildings_gdf, unit_area, on=\"zoning\", how=\"outer\")\n",
    "vacant_buildings_gdf = pd.merge(vacant_buildings_gdf, unit_area, on=\"zoning\", how=\"outer\")\n",
    "\n",
    "#update sqft based on far\n",
    "sale_buildings_gdf[\"sq_ft_far\"] = sale_buildings_gdf[\"SqFt\"]*sale_buildings_gdf[\"FAR\"]\n",
    "vacant_buildings_gdf[\"sq_ft_far\"] = vacant_buildings_gdf[\"SqFt\"]*vacant_buildings_gdf[\"FAR\"]\n",
    "\n",
    "\n",
    "#for non residential zoned lots, calculate sq footage above ground floor\n",
    "sale_buildings_gdf[\"sq_ft_residential\"] = np.where((sale_buildings_gdf[\"ZONE_CAT\"]==\"B-Business\") |\n",
    "                                               (sale_buildings_gdf[\"ZONE_CAT\"]==\"C-Commercial\"), \n",
    "                                               sale_buildings_gdf[\"sq_ft_far\"] - sale_buildings_gdf[\"SqFt\"], \n",
    "                                               sale_buildings_gdf[\"sq_ft_far\"])\n",
    "\n",
    "#assume 720 sq. ft. average unit size unless min unit size is larger\n",
    "sale_buildings_gdf[\"avg_unit_size\"] = np.where(sale_buildings_gdf[\"lot_area_per_unit\"] > 720, \n",
    "                                           sale_buildings_gdf[\"lot_area_per_unit\"], 720)\n",
    "\n",
    "#for non residential zoned lots, calculate sq footage above ground floor\n",
    "vacant_buildings_gdf[\"sq_ft_residential\"] = np.where((vacant_buildings_gdf[\"ZONE_CAT\"]==\"B-Business\") |\n",
    "                                               (vacant_buildings_gdf[\"ZONE_CAT\"]==\"C-Commercial\"), \n",
    "                                               vacant_buildings_gdf[\"sq_ft_far\"] - vacant_buildings_gdf[\"SqFt\"], \n",
    "                                               vacant_buildings_gdf[\"sq_ft_far\"])\n",
    "\n",
    "#assume 720 sq. ft. average unit size unless min unit size is larger\n",
    "vacant_buildings_gdf[\"avg_unit_size\"] = np.where(vacant_buildings_gdf[\"lot_area_per_unit\"] > 720, \n",
    "                                           vacant_buildings_gdf[\"lot_area_per_unit\"], 720)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# calculate estimate of number of units per lot\n",
    "# 0 units if residential eligible sq ft is smaller than minimum unit size\n",
    "sale_buildings_gdf[\"n_units\"] = np.where(sale_buildings_gdf[\"avg_unit_size\"] > sale_buildings_gdf[\"sq_ft_residential\"], 0, np.nan)\n",
    "\n",
    "# divide residential eligible sq ft by average unit size for all others and round down\n",
    "sale_buildings_gdf[\"n_units\"] = np.where(sale_buildings_gdf[\"n_units\"].isna(), \n",
    "                                     np.floor(sale_buildings_gdf[\"sq_ft_residential\"]/sale_buildings_gdf[\"avg_unit_size\"]), \n",
    "                                     sale_buildings_gdf[\"n_units\"])\n",
    "\n",
    "# 1 unit for single family\n",
    "sale_buildings_gdf[\"n_units\"] = np.where(sale_buildings_gdf[\"zoning\"].isin([\"RS-1\", \"RS-2\", \"RS-3\"]), 1, sale_buildings_gdf[\"n_units\"])\n",
    "\n",
    "# calculate estimate of number of units per lot\n",
    "# 0 units if residential eligible sq ft is smaller than minimum unit size\n",
    "vacant_buildings_gdf[\"n_units\"] = np.where(vacant_buildings_gdf[\"avg_unit_size\"] > vacant_buildings_gdf[\"sq_ft_residential\"], 0, np.nan)\n",
    "\n",
    "# divide residential eligible sq ft by average unit size for all others and round down\n",
    "vacant_buildings_gdf[\"n_units\"] = np.where(vacant_buildings_gdf[\"n_units\"].isna(), \n",
    "                                     np.floor(vacant_buildings_gdf[\"sq_ft_residential\"]/vacant_buildings_gdf[\"avg_unit_size\"]), \n",
    "                                     vacant_buildings_gdf[\"n_units\"])\n",
    "\n",
    "# 1 unit for single family\n",
    "vacant_buildings_gdf[\"n_units\"] = np.where(vacant_buildings_gdf[\"zoning\"].isin([\"RS-1\", \"RS-2\", \"RS-3\"]), 1, vacant_buildings_gdf[\"n_units\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(sale_buildings_gdf[\"n_units\"].sum(skipna=True)+vacant_buildings_gdf[\"n_units\"].sum(skipna=True))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
